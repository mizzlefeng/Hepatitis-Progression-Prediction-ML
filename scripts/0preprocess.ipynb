{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Data Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data = pd.read_excel(\"../data/raw_data.xlsx\")\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "treatment_protocol_col = '治疗方案（药物和剂量）'\n",
    "df = data.join(pd.DataFrame(mlb.fit_transform(data.pop(treatment_protocol_col)),\n",
    "                          columns=mlb.classes_,\n",
    "                          index=data.index))\n",
    "df.to_csv(\"../result/00pre-processing/01base_data.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Missing Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data = pd.read_csv(\"../result/00pre-processing/01base_data.csv\")\n",
    "missing_ratio = data.isna().mean()\n",
    "selected_features = missing_ratio[missing_ratio < 0.4].index\n",
    "final_data = data[selected_features]\n",
    "final_data.drop(columns=['name'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Imputation Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_data.copy(deep=True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from missingpy import MissForest\n",
    "from src.common import setup_seed\n",
    "import seaborn as sns\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "df_no_miss = df.dropna()\n",
    "df_no_miss_no_label = df_no_miss.drop(['half-year label','one-year label'],axis=1)\n",
    "nolabel_df = df.drop(['half-year label','one-year label'],axis=1)\n",
    "missing_ratio = nolabel_df.isna().mean()\n",
    "row_num, index_num = df_no_miss_no_label.shape\n",
    "\n",
    "miss_num = round(row_num * missing_ratio, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log_mse definition\n",
    "def log_mse(original, imputed, epsilon=1e-8):\n",
    "    log_original = np.log(original + epsilon)\n",
    "    log_imputed = np.log(imputed + epsilon)\n",
    "    return ((log_original - log_imputed) ** 2).mean(axis=0)\n",
    "\n",
    "# Imputation ways\n",
    "strategies = {\n",
    "    \"Mean\": SimpleImputer(strategy=\"mean\"),\n",
    "    \"Zero\": SimpleImputer(strategy=\"constant\", fill_value=0),\n",
    "    \"Median\": SimpleImputer(strategy=\"median\"),\n",
    "    \"Mode\": SimpleImputer(strategy=\"most_frequent\"),\n",
    "    \"KNN\": KNNImputer(n_neighbors=5),\n",
    "    \"Iter\": IterativeImputer(random_state=42),\n",
    "    \"RF\": MissForest(criterion='squared_error',max_features='sqrt',max_iter=100,verbose=0),\n",
    "}\n",
    "\n",
    "setup_seed(42)\n",
    "n_experiments = 5\n",
    "results_modified_msre = {strategy: [] for strategy in strategies}\n",
    "results_log_mse = {strategy: [] for strategy in strategies}\n",
    "\n",
    "for _ in range(n_experiments):\n",
    "    init_df = df_no_miss_no_label.copy(deep=True)\n",
    "    for feature, missing_count in miss_num.items():\n",
    "        if int(missing_count)==0:\n",
    "            continue\n",
    "        else:\n",
    "            missing_indices = random.sample(list(df_no_miss_no_label.index), int(missing_count))\n",
    "            init_df.loc[missing_indices, feature] = np.nan\n",
    "\n",
    "    for name, imputer in strategies.items():\n",
    "        df_imputed = pd.DataFrame(imputer.fit_transform(init_df), columns=init_df.columns, index=init_df.index)\n",
    "        log_mse_score = log_mse(df_no_miss_no_label, df_imputed).mean()\n",
    "        results_log_mse[name].append(log_mse_score)\n",
    "\n",
    "log_mse_means = {name: np.mean(scores) for name, scores in results_log_mse.items()}\n",
    "log_mse_stds = {name: np.std(scores) for name, scores in results_log_mse.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7), facecolor='none')\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "\n",
    "methods = list(log_mse_means.keys())\n",
    "means = np.array(list(log_mse_means.values()))\n",
    "stds = np.array(list(log_mse_stds.values()))\n",
    "\n",
    "sorted_indices = np.argsort(means)[::-1]\n",
    "methods = np.array(methods)[sorted_indices]\n",
    "means = means[sorted_indices]\n",
    "stds = stds[sorted_indices]\n",
    "ax = sns.barplot(x=means, y=methods, palette=\"viridis\", orient='h',linewidth=1,edgecolor='black',width=0.6)\n",
    "\n",
    "# Add error bar\n",
    "for i, (mean, std) in enumerate(zip(means, stds)):\n",
    "    ax.errorbar(mean, i, xerr=std, fmt='none', c='black', capsize=5, elinewidth=1.5)\n",
    "    if i == len(means) - 1:\n",
    "        ax.axvline(x=mean, color='gray', linestyle='--', label='min LogMSE',linewidth=2.5)\n",
    "        ax.legend(loc=\"lower right\",prop={'weight': 'bold', 'size': 12})\n",
    "\n",
    "# Add text annotation\n",
    "for i, (mean, std) in enumerate(zip(means, stds)):\n",
    "    ax.text(mean + std+0.05, i, f'{mean:.2f}±{std:.2f}', va='center', c='black')\n",
    "\n",
    "for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "    label.set_fontweight('bold')\n",
    "# plt.title(\"Log MSE Evaluation\", fontsize=16, fontweight='bold', c='k')\n",
    "plt.xlabel('Log MSE', fontsize=14, fontweight='bold', c='k')\n",
    "plt.ylabel(\"Imputation Method\", fontsize=14, fontweight='bold', c='k')\n",
    "\n",
    "plt.tick_params(axis='x', colors='k', labelsize=12)\n",
    "plt.tick_params(axis='y', colors='k', labelsize=12)\n",
    "ax.set_xlim(0, 14)\n",
    "ax = plt.gca()  # Obtain the current axis\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_linewidth(2) # bold the x-axis\n",
    "ax.spines['left'].set_linewidth(2)\n",
    "\n",
    "ax.xaxis.set_tick_params(width=2) # bold the scale\n",
    "ax.yaxis.set_tick_params(width=2)\n",
    "ax.set_facecolor('none')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"../result/00pre-processing/02impute_way_compare_origin_miss_ratio.pdf\",dpi=300,bbox_inches=\"tight\",format='pdf')\n",
    "plt.savefig(\"../result/00pre-processing/02impute_way_compare_origin_miss_ratio.tif\",dpi=300,bbox_inches=\"tight\",format='tif')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "import joblib\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "imputer.fit(final_data)\n",
    "joblib.dump(imputer, '../result/00pre-processing/knn_imputer_model.pkl')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(final_data), columns=final_data.columns, index=final_data.index)\n",
    "df_imputed['e抗原COI'] = df_imputed['e抗原COI'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "df_imputed.to_csv(\"../result/00pre-processing/02no_miss_data.csv\",index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Select Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif\n",
    "from scipy.stats import rankdata\n",
    "data = pd.read_csv(\"../result/00pre-processing/02no_miss_data.csv\")\n",
    "df = data.copy(deep=True)\n",
    "\n",
    "df = df[['Gender', 'Age', 'Subtype', 'ALT', 'AST', 'TProt', 'Albumin', 'Globulin', 'GGT', 'DBIL',\n",
    "       'IBIL', 'AFP', 'DNA load', 'HBsAg', 'HBeAg_COI', 'SFU', 'HBsAg1_T', 'HBsAg2_T', \n",
    "       'HBpol1_T', 'HBpol2_T', 'HBx1_T', 'HBx2_T', 'HBeAg1_T', 'HBeAg2_T', 'ThSched', 'ADV', 'ETV', 'PEG_IFN', 'TAF', 'TDF', \n",
    "       'TFV', 'TMF', 'UnusedD' ,'6M-Label','12M-Label']]\n",
    "clinical_features = ['Gender', 'Age', 'ALT', 'AST', 'TProt', 'Albumin', 'Globulin', 'GGT', 'DBIL', \n",
    "                     'IBIL', 'AFP', 'DNA load', 'HBsAg', 'HBeAg_COI', ]\n",
    "\n",
    "def calculate_feature_ranks(x, y, features):\n",
    "    \"\"\"\n",
    "    Calculate the rank of the three ways\n",
    "    \"\"\"\n",
    "    # chi2\n",
    "    chi2_stat, p_values = chi2(x, y)\n",
    "    chi2_df = pd.DataFrame({'Feature': features, 'Chi2_Stat': chi2_stat})\n",
    "    chi2_df['Chi2_Rank'] = len(features) - rankdata(chi2_stat) + 1\n",
    "    \n",
    "    # pearson\n",
    "    correlation = pd.concat([x, y], axis=1).corr()[y.name].drop(y.name)\n",
    "    corr_df = pd.DataFrame({'Feature': correlation.index, 'Correlation': correlation.values})\n",
    "    corr_df['Correlation_Rank'] = len(features) - rankdata(abs(correlation.values)) + 1\n",
    "    \n",
    "    # mutual info\n",
    "    mutual_info = mutual_info_classif(x, y, random_state=42)\n",
    "    mi_df = pd.DataFrame({'Feature': features, 'Mutual_Info': mutual_info})\n",
    "    mi_df['MI_Rank'] = len(features) - rankdata(mutual_info) + 1\n",
    "    \n",
    "    result = chi2_df.merge(corr_df, on='Feature').merge(mi_df, on='Feature')\n",
    "    result['Avg_Rank'] = (result['Chi2_Rank'] + result['Correlation_Rank'] + result['MI_Rank']) / 3\n",
    "    result['Final_Rank'] = rankdata(result['Avg_Rank'])\n",
    "    # print(result)\n",
    "    \n",
    "    return result.sort_values('Final_Rank')\n",
    "\n",
    "x = df[clinical_features]\n",
    "y_6m = df['6M-Label']\n",
    "y_12m = df['12M-Label']\n",
    "\n",
    "# calculate the ranking of the features at two time point \n",
    "print(\"calculate the ranking of the features at 6M...\")\n",
    "rank_6m = calculate_feature_ranks(x, y_6m, clinical_features)\n",
    "\n",
    "print(\"calculate the ranking of the features at 12M...\")\n",
    "rank_12m = calculate_feature_ranks(x, y_12m, clinical_features)\n",
    "\n",
    "merged_ranks = rank_6m[['Feature', 'Final_Rank']].merge(\n",
    "    rank_12m[['Feature', 'Final_Rank']], \n",
    "    on='Feature', \n",
    "    suffixes=('_6M', '_12M')\n",
    ")\n",
    "\n",
    "# calculate the overall ranking\n",
    "merged_ranks['Combined_Rank'] = (merged_ranks['Final_Rank_6M'] + merged_ranks['Final_Rank_12M']) / 2\n",
    "merged_ranks['Final_Combined_Rank'] = rankdata(merged_ranks['Combined_Rank'], method='min')\n",
    "\n",
    "all_features = merged_ranks\n",
    "\n",
    "detailed_results = all_features.merge(\n",
    "    rank_6m[['Feature', 'Chi2_Stat', 'Correlation', 'Mutual_Info', 'Avg_Rank']].rename(\n",
    "        columns={'Avg_Rank': 'Avg_Rank_6M'}\n",
    "    ), on='Feature'\n",
    ").merge(\n",
    "    rank_12m[['Feature', 'Chi2_Stat', 'Correlation', 'Mutual_Info', 'Avg_Rank']].rename(\n",
    "        columns={'Avg_Rank': 'Avg_Rank_12M'}\n",
    "    ), on='Feature', suffixes=('_6M', '_12M')\n",
    ")\n",
    "\n",
    "detailed_results.to_excel(\"../result/00pre-processing/03all_features_combined.xlsx\", index=False, engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_features = ['Gender', 'ALT', 'AST', 'Albumin', 'GGT', 'DBIL', 'IBIL', 'AFP', 'DNA load', 'HBsAg', 'SFU', 'HBsAg1_T', 'HBsAg2_T', \n",
    "       'HBpol1_T', 'HBpol2_T', 'HBx1_T', 'HBx2_T', 'HBeAg1_T', 'HBeAg2_T', 'ThSched', 'ADV', 'ETV', 'PEG_IFN', 'TAF', 'TDF', \n",
    "       'TFV', 'TMF','6M-Label','12M-Label']\n",
    "df=df[select_features]\n",
    "STCF_mapping = {\n",
    "    \"HBsAg1_T\": \"HBsAg-T(pH>7)\", \"HBsAg2_T\": \"HBsAg-T(pH≤7)\", \n",
    "    \"HBpol1_T\": \"HBpol-T(pH>7)\", \"HBpol2_T\": \"HBpol-T(pH≤7)\", \n",
    "    \"HBx1_T\": \"HBx-T(pH>7)\", \"HBx2_T\": \"HBx-T(pH≤7)\", \n",
    "    \"HBeAg1_T\": \"HBeAg-T(pH>7)\", \"HBeAg2_T\": \"HBeAg-T(pH≤7)\", \n",
    "    'HBeAg COI': \"HBeAg\",\n",
    "    'PEG_IFN': \"PEG-IFN\",\n",
    "    'SFU': \"HBV-T\"\n",
    "    }\n",
    "\n",
    "df.rename(columns=STCF_mapping, inplace=True)\n",
    "df.to_csv(\"../result/00pre-processing/03feature_select_data.csv\",index=False,encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv(\"../result/00pre-processing/03feature_select_data.csv\")\n",
    "\n",
    "clinical_features = ['Gender', 'ALT', 'AST', 'Albumin', 'GGT', 'DBIL', 'IBIL', 'AFP', 'DNA load', 'HBsAg']\n",
    "specific_features = ['HBV-T', 'HBsAg-T(pH>7)', 'HBsAg-T(pH≤7)', 'HBpol-T(pH>7)', 'HBpol-T(pH≤7)', 'HBx-T(pH>7)', 'HBx-T(pH≤7)', 'HBeAg-T(pH>7)', 'HBeAg-T(pH≤7)']\n",
    "treat_features = ['ThSched', 'ADV', 'ETV', 'PEG-IFN', 'TAF', 'TDF', 'TFV', 'TMF']\n",
    "\n",
    "df = df[clinical_features+specific_features+treat_features+['6M-Label','12M-Label']]\n",
    "\n",
    "df_scaler = df.copy(deep=True)\n",
    "df_scaler.drop(['6M-Label','12M-Label'], axis=1, inplace=True)\n",
    "\n",
    "minmax_transfer = MinMaxScaler()\n",
    "df_scaler_minmax = minmax_transfer.fit_transform(df_scaler)\n",
    "joblib.dump(minmax_transfer, \"../result/00pre-processing/scaler.joblib\")\n",
    "\n",
    "df_scaler = pd.DataFrame(df_scaler_minmax, columns=df_scaler.columns)\n",
    "df_scaler[['6M-Label','12M-Label']] = df[['6M-Label','12M-Label']]\n",
    "\n",
    "df_scaler.to_csv(\"../result/00pre-processing/05final_data-minmax.csv\", index=False, encoding=\"utf-8-sig\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mizzle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
