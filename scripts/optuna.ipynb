{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single classifier optuna optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from src.common import init_logger,setup_seed\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import warnings\n",
    "import json\n",
    "import itertools\n",
    "import optuna\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optuna configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "CV_RESULT = \"\"\n",
    "LOGFILE = f\"01model_optuna_f1.log\"\n",
    "\n",
    "logger,file_handler = init_logger(LOGFILE)\n",
    "\n",
    "def my_svm(**params):\n",
    "    return SVC(probability=True, **params)\n",
    "\n",
    "def my_lgb(**params):\n",
    "    return LGBMClassifier(verbose=-1, **params)\n",
    "\n",
    "model_dict = {\n",
    "    \"LR\": LogisticRegression,\n",
    "    \"SVM\": my_svm,\n",
    "    \"NB\": GaussianNB,\n",
    "    \"KNN\": KNeighborsClassifier,\n",
    "    \"RF\": RandomForestClassifier,\n",
    "    \"XGBoost\": XGBClassifier,\n",
    "    \"LightGBM\": my_lgb,\n",
    "}\n",
    "\n",
    "clinical_features = ['Gender', 'ALT', 'AST', 'Globulin', 'DBIL', 'IBIL', 'AFP', 'DNA load', 'HBsAg', 'HBeAg_COI']\n",
    "specific_features = ['SFU', 'HBsAg1_T', 'HBsAg2_T', 'HBpol1_T', 'HBpol2_T', 'HBx1_T', 'HBx2_T', 'HBeAg1_T', 'HBeAg2_T']\n",
    "treat_features = ['ThSched', 'ADV', 'ETV', 'PEG_IFN', 'TAF', 'TDF', 'TFV', 'TMF', 'UnusedD']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn traditional machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_seed(42)\n",
    "config = load_config('../config/ml_config.json')\n",
    "storage_name = \"postgresql://postgres:xxx@127.0.0.1/hep_f1\"\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def ml_optimize_model(X, y, model_name, feature_group, n_trials=50):\n",
    "    def objective(trial):\n",
    "        try:\n",
    "            params = {}\n",
    "            for param_name, param_info in config[model_name].items():\n",
    "                param_method = getattr(trial, param_info[\"type\"])\n",
    "                params[param_name] = param_method(param_name, *param_info[\"args\"])\n",
    "            \n",
    "            auc_list = []\n",
    "            for train_index, test_index in skf.split(X, y):\n",
    "                model_constructor = model_dict[model_name]\n",
    "                model = model_constructor(**params)\n",
    "                X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                y_pred = model.predict(X_test)\n",
    "                f1 = f1_score(y_test, y_pred)\n",
    "                auc_list.append(f1)\n",
    "\n",
    "            return np.mean(auc_list)\n",
    "        except Exception as e:\n",
    "            trial.report(float('-inf'), step=0)\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    study = optuna.create_study(study_name=feature_group+\"_\"+model_name, storage=storage_name, direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials, n_jobs=-1)\n",
    "    return study.best_params, study.best_value, study\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from ..src.deep_model import FCN, CNN, train_evaluate\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "device = torch.device(f'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def dl_optimize_model(X, y, model_name, feature_group, n_trials=50):\n",
    "\n",
    "    def objective(trial):\n",
    "        if model_name == \"FCN\":\n",
    "            lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "            n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "            hidden_layers = [trial.suggest_categorical(f\"n_units_l{i}\", [16, 32, 64, 128, 256]) for i in range(n_layers)]\n",
    "            activation_func = trial.suggest_categorical('activation_func', ['relu', 'tanh', 'sigmoid'])\n",
    "            optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'SGD','AdamW'])\n",
    "            \n",
    "            f1_list = []\n",
    "            for train_index, test_index in skf.split(X, y):\n",
    "                setup_seed(42)\n",
    "                X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "                model = FCN(input_dim=X.shape[1], output_dim=1, hidden_layers=hidden_layers, activation_func=activation_func).to(device)\n",
    "                optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "                criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "                f1 = train_evaluate(model, criterion, optimizer, X_train, y_train, X_val, y_val)\n",
    "                f1_list.append(f1)\n",
    "\n",
    "            return np.mean(f1_list)\n",
    "        \n",
    "        elif model_name == \"CNN\":\n",
    "            lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "            n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "            n_filters = [trial.suggest_categorical(f\"n_filters_l{i}\", [16, 32, 64, 128]) for i in range(n_layers)]\n",
    "            kernel_size = trial.suggest_categorical(\"kernel_size\", [3, 5, 7])\n",
    "            activation_func = trial.suggest_categorical('activation_func', ['relu', 'tanh', 'sigmoid'])\n",
    "            optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'SGD','AdamW'])\n",
    "            \n",
    "            f1_list = []\n",
    "            for train_index, test_index in skf.split(X, y):\n",
    "                setup_seed(42)\n",
    "                X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "                y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "                model = CNN(n_features=X.shape[1], output_dim=1, n_layers=n_layers, n_filters=n_filters, kernel_size=kernel_size, activation_func=activation_func).to(device)\n",
    "                optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "                criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "                f1 = train_evaluate(model, criterion, optimizer, X_train, y_train, X_val, y_val)\n",
    "                f1_list.append(f1)\n",
    "\n",
    "            return np.mean(f1_list)\n",
    "\n",
    "        else:\n",
    "            NotImplementedError\n",
    "\n",
    "    study = optuna.create_study(study_name=feature_group+\"_\"+model_name, storage=storage_name, direction='maximize')\n",
    "    study.optimize(objective, n_trials=n_trials, n_jobs=-1)\n",
    "    return study.best_params, study.best_value, study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_seed(42)\n",
    "data = pd.read_csv('')\n",
    "y = data['Label']\n",
    "model_list = []\n",
    "\n",
    "feature_dict = {\n",
    "    \"CIF\": clinical_features,\n",
    "    \"STCF\": specific_features,\n",
    "    \"TPF\": treat_features\n",
    "}\n",
    "\n",
    "feature_names = list(feature_dict.keys())\n",
    "combinations_1 = list(itertools.combinations(feature_names, 1))\n",
    "combinations_2 = list(itertools.combinations(feature_names, 2))\n",
    "combinations_3 = list(itertools.combinations(feature_names, 3))\n",
    "all_combinations = combinations_1 + combinations_2 + combinations_3\n",
    "all_combinations\n",
    "\n",
    "for combo in all_combinations:\n",
    "\n",
    "    combined_features = []\n",
    "    for group in combo:\n",
    "        combined_features.extend(feature_dict[group])\n",
    "    feature_group = ' + '.join([g for g in combo])\n",
    "    logger.info(\"#\"*50)\n",
    "    logger.info(feature_group)\n",
    "    X = data[combined_features]\n",
    "    for model_name in model_dict.keys():\n",
    "        best_params, best_score, study = ml_optimize_model(X, y, model_name, feature_group, n_trials=200)\n",
    "        logger.info(f\"{model_name} Best parameters: {best_params}\")\n",
    "        logger.info(f\"{model_name} Best score: {best_score}\")\n",
    "    \n",
    "    for model_name in ['FCN','CNN']:\n",
    "        best_params, best_score, study = dl_optimize_model(X, y, model_name, feature_group, n_trials=200)\n",
    "        logger.info(f\"{model_name} Best parameters: {best_params}\")\n",
    "        logger.info(f\"{model_name} Best score: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_handler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!optuna-dashboard --host 0.0.0.0 --port 8083 postgresql://postgres:123...@127.0.0.1/hep_f1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mizzle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
