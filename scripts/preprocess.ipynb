{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 Data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data = pd.read_excel(\"../data/raw_data.xlsx\")\n",
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Processing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../result/00pre-processing/01base_data.csv\")\n",
    "clinical_features = [\n",
    "    \"Gender\",\n",
    "    \"Age\",\n",
    "    \"ALT\",\n",
    "    \"AST\",\n",
    "    \"TProt\",\n",
    "    \"Albumin\",\n",
    "    \"Globulin\",\n",
    "    \"ALP\",\n",
    "    \"GGT\",\n",
    "    \"DBIL\",\n",
    "    \"IBIL\",\n",
    "    \"AFP\",\n",
    "    \"DNA load\",\n",
    "    \"HBsAg\",\n",
    "    \"HBsAb\",\n",
    "    \"HBeAg_COI\",\n",
    "    \"HBeAb_COI\",\n",
    "    \"HBcAb_COI\",\n",
    "    \"Subtype\",\n",
    "]\n",
    "treat_features = [\n",
    "    \"ThSched\",\n",
    "    \"ADV\",\n",
    "    \"ETV\",\n",
    "    \"PEG-IFN\",\n",
    "    \"TAF\",\n",
    "    \"TDF\",\n",
    "    \"TFV\",\n",
    "    \"TMF\",\n",
    "    \"UnusedD\",\n",
    "]\n",
    "specific_features = [\n",
    "    \"HBV-T\",\n",
    "    \"HBsAg1_T\",\n",
    "    \"HBsAg2_T\",\n",
    "    \"HBpol1_T\",\n",
    "    \"HBpol2_T\",\n",
    "    \"HBx1_T\",\n",
    "    \"HBx2_T\",\n",
    "    \"HBeAg1_T\",\n",
    "    \"HBeAg2_T\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_ratio = data.isna().mean()\n",
    "selected_features = missing_ratio[missing_ratio < 0.4].index\n",
    "final_data = data[selected_features]\n",
    "final_data.drop(columns=[\"name\"], inplace=True)\n",
    "\n",
    "print(\"Selected features:\", selected_features)\n",
    "print(\"Filtered data shape:\", final_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of filling methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_data.copy()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "df_no_miss = df.dropna()\n",
    "print(df_no_miss[\"label\"].value_counts())\n",
    "df_no_miss_no_label = df_no_miss.drop([\"label\"], axis=1, inplace=False)\n",
    "\n",
    "df.drop([\"label\"], axis=1, inplace=True)\n",
    "missing_ratio = df.isna().mean()\n",
    "df_miss = df_no_miss_no_label.copy(deep=True)\n",
    "row_num, index_num = df_no_miss_no_label.shape\n",
    "miss_num = round(row_num * missing_ratio, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from missingpy import MissForest\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tools.common import setup_seed\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "# log_mse\n",
    "def log_mse(original, imputed, epsilon=1e-8):\n",
    "    log_original = np.log(original + epsilon)\n",
    "    log_imputed = np.log(imputed + epsilon)\n",
    "    return ((log_original - log_imputed) ** 2).mean(axis=0)\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64), nn.ReLU(), nn.Linear(64, 16), nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16, 64), nn.ReLU(), nn.Linear(64, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "def autoencoder_impute(df, num_epochs=300, batch_size=64):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    input_dim = df.shape[1]\n",
    "\n",
    "    imputer = SimpleImputer(strategy=\"mean\")\n",
    "    df_filled = imputer.fit_transform(df)\n",
    "\n",
    "    data = torch.tensor(df_filled, dtype=torch.float32).to(device)\n",
    "    data_loader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = Autoencoder(input_dim).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = torch.nn.MSELoss()\n",
    "\n",
    "    model.train()\n",
    "    for _ in range(num_epochs):\n",
    "        for batch in data_loader:\n",
    "            imputed = batch.clone()\n",
    "            # imputed[torch.isnan(batch)] = 0\n",
    "            optimizer.zero_grad()\n",
    "            output = model(imputed)\n",
    "            loss = criterion(output, batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        imputed_data = model(data).cpu().numpy()\n",
    "\n",
    "    df_imputed = df.copy()\n",
    "    mask = df.isna()\n",
    "    imputed_data = pd.DataFrame(imputed_data, columns=df.columns, index=df.index)\n",
    "    df_imputed[mask] = imputed_data[mask]\n",
    "\n",
    "    return df_imputed\n",
    "\n",
    "\n",
    "strategies = {\n",
    "    \"Mean\": SimpleImputer(strategy=\"mean\"),\n",
    "    \"Zero\": SimpleImputer(strategy=\"constant\", fill_value=0),\n",
    "    \"Median\": SimpleImputer(strategy=\"median\"),\n",
    "    \"Mode\": SimpleImputer(strategy=\"most_frequent\"),\n",
    "    \"KNN\": KNNImputer(n_neighbors=5),\n",
    "    \"Iter\": IterativeImputer(random_state=42),\n",
    "    \"RF\": MissForest(criterion=\"squared_error\", max_features=\"sqrt\", max_iter=100),\n",
    "    \"AE\": autoencoder_impute,\n",
    "}\n",
    "\n",
    "setup_seed(42)\n",
    "n_experiments = 5\n",
    "results_modified_msre = {strategy: [] for strategy in strategies}\n",
    "results_log_mse = {strategy: [] for strategy in strategies}\n",
    "\n",
    "for _ in range(n_experiments):\n",
    "    df_miss = df_no_miss_no_label.copy(deep=True)\n",
    "    for feature, missing_count in miss_num.items():\n",
    "\n",
    "        if int(missing_count) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            missing_indices = random.sample(\n",
    "                list(df_no_miss_no_label.index), int(missing_count)\n",
    "            )\n",
    "            df_miss.loc[missing_indices, feature] = np.nan\n",
    "\n",
    "    for name, imputer in strategies.items():\n",
    "        if name in [\"AE\"]:\n",
    "            df_imputed = imputer(df_miss)\n",
    "        else:\n",
    "            df_imputed = pd.DataFrame(\n",
    "                imputer.fit_transform(df_miss),\n",
    "                columns=df_miss.columns,\n",
    "                index=df_miss.index,\n",
    "            )\n",
    "\n",
    "        modified_msre_score = modified_msre(df_no_miss_no_label, df_imputed).mean()\n",
    "        log_mse_score = log_mse(df_no_miss_no_label, df_imputed).mean()\n",
    "        results_modified_msre[name].append(modified_msre_score)\n",
    "        results_log_mse[name].append(log_mse_score)\n",
    "\n",
    "msre_means = {name: np.mean(scores) for name, scores in results_modified_msre.items()}\n",
    "msre_stds = {name: np.std(scores) for name, scores in results_modified_msre.items()}\n",
    "log_mse_means = {name: np.mean(scores) for name, scores in results_log_mse.items()}\n",
    "log_mse_stds = {name: np.std(scores) for name, scores in results_log_mse.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "methods = list(log_mse_means.keys())\n",
    "means = np.array(list(log_mse_means.values()))\n",
    "stds = np.array(list(log_mse_stds.values()))\n",
    "\n",
    "sorted_indices = np.argsort(means)[::-1]\n",
    "methods = np.array(methods)[sorted_indices]\n",
    "means = means[sorted_indices]\n",
    "stds = stds[sorted_indices]\n",
    "ax = sns.barplot(x=means, y=methods, palette=\"viridis\", orient=\"h\")\n",
    "\n",
    "ax.spines[\"bottom\"].set_linewidth(2)\n",
    "ax.spines[\"left\"].set_linewidth(2)\n",
    "\n",
    "for i, (mean, std) in enumerate(zip(means, stds)):\n",
    "    ax.errorbar(mean, i, xerr=std, fmt=\"none\", c=\"black\", capsize=5, elinewidth=1.5)\n",
    "\n",
    "for i, (mean, std) in enumerate(zip(means, stds)):\n",
    "    ax.text(mean + std + 0.05, i, f\"{mean:.2f}Â±{std:.2f}\", va=\"center\", c=\"black\")\n",
    "\n",
    "for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "    label.set_fontweight(\"bold\")\n",
    "# plt.title(\"Log MSE Evaluation\", fontsize=16, fontweight='bold', c='k')\n",
    "plt.xlabel(\"Log MSE\", fontsize=14, fontweight=\"bold\", c=\"k\")\n",
    "plt.ylabel(\"Imputation Method\", fontsize=14, fontweight=\"bold\", c=\"k\")\n",
    "plt.tick_params(axis=\"x\", colors=\"k\")\n",
    "plt.tick_params(axis=\"y\", colors=\"k\")\n",
    "plt.tick_params(axis=\"x\", labelcolor=\"k\")\n",
    "plt.tick_params(axis=\"y\", labelcolor=\"k\")\n",
    "ax.set_xlim(0, 14)\n",
    "ax = plt.gca()\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"bottom\"].set_linewidth(2)\n",
    "ax.spines[\"left\"].set_linewidth(2)\n",
    "\n",
    "ax.xaxis.set_tick_params(width=2)\n",
    "ax.yaxis.set_tick_params(width=2)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import mutual_info_classif, chi2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "method = [\"pearson\", \"spearman\"]\n",
    "correlation_matrix = df.corr(method=\"pearson\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "ax = sns.heatmap(\n",
    "    correlation_matrix,\n",
    "    annot=False,\n",
    "    cmap=\"bwr\",\n",
    "    annot_kws={\"size\": 12},\n",
    "    linewidths=1,\n",
    "    cbar_kws={\"shrink\": 0.5},\n",
    ")\n",
    "colorbar = ax.collections[0].colorbar\n",
    "\n",
    "colorbar.set_ticks([-0.8, 0.95])\n",
    "colorbar.set_ticklabels([\"Low\", \"High\"])\n",
    "colorbar.ax.tick_params(labelsize=12)\n",
    "colorbar.ax.set_aspect(15)\n",
    "for label in colorbar.ax.get_yticklabels():\n",
    "    label.set_fontname(\"Arial\")\n",
    "    label.set_fontweight(\"bold\")\n",
    "plt.xticks(fontsize=12, fontweight=\"bold\")\n",
    "plt.yticks(fontsize=12, fontweight=\"bold\")\n",
    "# plt.title(\"Correlation Heatmap\", fontsize=16, fontweight='bold',c='k')\n",
    "plt.tick_params(axis=\"x\", colors=\"k\")\n",
    "plt.tick_params(axis=\"y\", colors=\"k\")\n",
    "plt.tick_params(axis=\"x\", labelcolor=\"k\")\n",
    "plt.tick_params(axis=\"y\", labelcolor=\"k\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    \"../result/00pre-processing/03Correlation Heatmap.pdf\",\n",
    "    format=\"pdf\",\n",
    "    dpi=600,\n",
    "    bbox_inches=\"tight\",\n",
    ")\n",
    "plt.savefig(\n",
    "    \"../result/00pre-processing/03Correlation Heatmap.tif\", dpi=300, bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[clinical_features]\n",
    "y = df['Label']\n",
    "\n",
    "chi2_stat, p_values = chi2(x, y)\n",
    "chi2_df = pd.DataFrame({'Feature': x.columns, 'Chi2_Stat': chi2_stat, 'P_Value': p_values})\n",
    "chi2_df['Chi2_Stat'] = chi2_df['Chi2_Stat'].round(4)\n",
    "top10_chi2 = chi2_df.sort_values(by='Chi2_Stat', ascending=False).head(10)\n",
    "\n",
    "correlation = df[clinical_features + ['Label']].corr()['Label'].drop('Label')\n",
    "corr_df = pd.DataFrame({'Feature': correlation.index, 'Correlation': correlation.values})\n",
    "corr_df['Correlation'] = corr_df['Correlation'].round(4)\n",
    "top10_corr = corr_df.sort_values(by='Correlation', ascending=False).head(10)\n",
    "\n",
    "mutual_info = mutual_info_classif(x, y,random_state=42)\n",
    "mi_df = pd.DataFrame({'Feature': x.columns, 'Mutual_Info': mutual_info})\n",
    "mi_df['Mutual_Info'] = mi_df['Mutual_Info'].round(4)\n",
    "top10_mi = mi_df.sort_values(by='Mutual_Info', ascending=False).head(10)\n",
    "\n",
    "from collections import Counter\n",
    "all_top_features = list(top10_chi2['Feature']) + list(top10_mi['Feature']) + list(top10_corr['Feature'])\n",
    "feature_counts = Counter(all_top_features)\n",
    "\n",
    "final_top10_features = [feature for feature, count in feature_counts.most_common(10)]\n",
    "print(final_top10_features)\n",
    "drop_clinical_features = [item for item in clinical_features if item not in final_top10_features]\n",
    "feature_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=drop_clinical_features, inplace=True)\n",
    "df.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04 Data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv(\"\")\n",
    "\n",
    "clinical_features = ['Gender', 'ALT', 'AST', 'Globulin', 'DBIL', 'IBIL', 'AFP', 'DNA load', 'HBsAg', 'HBeAg_COI']\n",
    "specific_features = ['SFU', 'HBsAg1_T', 'HBsAg2_T', 'HBpol1_T', 'HBpol2_T', 'HBx1_T', 'HBx2_T', 'HBeAg1_T', 'HBeAg2_T']\n",
    "treat_features = ['ThSched', 'ADV', 'ETV', 'PEG_IFN', 'TAF', 'TDF', 'TFV', 'TMF', 'UnusedD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[clinical_features + specific_features + treat_features + [\"Label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaler = df.copy()\n",
    "df_scaler.drop([\"Label\"], axis=1, inplace=True)\n",
    "\n",
    "minmax_transfer = MinMaxScaler()\n",
    "df_scaler_minmax = minmax_transfer.fit_transform(df_scaler)\n",
    "joblib.dump(minmax_transfer, \"scaler.joblib\")\n",
    "\n",
    "df_scaler = pd.DataFrame(df_scaler_minmax, columns=df_scaler.columns)\n",
    "df_scaler[\"Label\"] = df[\"Label\"]\n",
    "\n",
    "df_scaler.to_csv(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mizzle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
